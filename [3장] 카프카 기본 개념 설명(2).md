# [3장] 카프카 기본 개념 설명(2)

# 3.5 카프카 스트림즈

- 토픽에 적재된 데이터를 실시간으로 변환하여 다른 토픽에 적재하는 라이브러리
- 카프카 스트림즈는 카프카 클러스터와 완벽하게 호환되면서 스트림 처리에 필요한 편리한 기능들(신규 토픽 생성, 상태 저장, 데이터 조인 등)을 제공한다.
- 스트림즈 애플리케이션 또는 카프카 브로커의 장애가 발생하더라도 정확히 한 번(exactly once)할 수 있도록 장애 허용 시스템을 가지고 있어 데이터 처리 안정성이 매우 뛰어나다.
- **카프카 클러스터 운영 + 실시간 스트림 처리**

![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/db1663d5-6de9-4971-9a74-689e3b2b862d/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T081914Z&X-Amz-Expires=86400&X-Amz-Signature=327d964111d110a978127448c3d32329649b3b239e02fe03ab89b98d2514bcb3&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- 스트림즈 애플리케이션은 내부적으로 스레드를 1개 이상 생성할 수 있으며, 스레드는 1개 이상의 태스크를 가진다.
- '태스크(task)': 스트림즈를 실행하면 생기는 데이터 처리 최소 단위 (3개의 파티션으로 이루어진 토픽 처리 → 3개의 태스크 생성)
- 실제 운영환경에서는 안정적인 운영을 위해 2개 이상의 서버로 구성하여 스트림즈 애플리케이션을 운영한다.

### 카프카 스트림즈의 구조와 사용 방법

- 토폴로지(topology): 2개 이상의 노드들과 선으로 이루어진 집합.
- 스트림즈에서는 트리형 토폴로지와 유사한 형태의 토폴로지를 사용한다.
- 프로세서(processor): 카프카 스트림즈에서 토폴로지를 이루는 노드
    1. 소스 프로세서

        데이터를 처리하기 위해 최초로 선언해야 하는 노드로, 하나 이상의 토픽에서 데이터를 가져오는 역할

    2. 스트림 프로세서

        다른 프로세서가 반환한 데이터를 처리(변환, 분기처리 등)하는 역할

    3. 싱크 프로세서

        데이터를 특정 카프카 토픽으로 저장하는 역할. 스트림즈로 처리된 데이터의 최종 종착지.

- 스트림(stream): 노드와 노드를 이은 선. 토픽의 데이터를 뜻하며, 프로듀서와 컨슈머에서 활용했던 레코드와 동일하다.
- 스트림즈DSL과 프로세서 API 2가지 방법으로 개발 가능
    1. 스트림즈DSL

        스트림 프로세싱에 쓰일 만한 다양한 기능들을 자체 API로 만들어둠

        - 메시지 값을 기반으로 토픽 분기처리
        - 지난 10분간 들어온 데이터의 개수 집계
        - 토픽과 다른 토픽의 결합으로 새로운 데이터 생성
    2. 프로세서 API

        스트림즈DSL에서 제공하지 않는 일부 기능들을 프로세서 API에서 구현 가능

        - 메시지 값의 종류에 따라 토픽을 가변적으로 전송
        - 일정한 시간 간격으로 데이터 처리

## 3.5.1 스트림즈DSL

### KStream

- 레코드의 흐름을 표현한 것으로 메시지 키와 메시지 값으로 구성되어 있다.
- KStream으로 데이터를 조회하면 토픽에 존재하는 모든 레코드가 출력된다.
- 컨슈머로 토픽을 구독하는 것과 동일한 선상에서 사용

![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%201.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/348c1826-08ed-4e3e-b485-11a39869ddf0/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T081923Z&X-Amz-Expires=86400&X-Amz-Signature=aa4d412e40bcffcf6eddd3aafcd34a82f727604874a5b16ac454c140c3fd4d55&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

### KTable

- 메시지 키를 기준으로 묶어서 사용한다.
- 유니크한 메시지 키를 기준으로 가장 최신 레코드를 사용한다.
- 새로 데이터를 적재할 대 동일한 메시지 키가 있을 경우 데이터가 업데이트되었다고 볼 수 있다.

![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%202.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f6c0738c-f8b9-4f74-9807-e6b263aa2e97/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T081932Z&X-Amz-Expires=86400&X-Amz-Signature=69a6763686d8c731e7eaafd86d61c52873266e3a5212a79bf9e3c596239f2147&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

### GlobalKTable

- KTable과 동일하게 메시지 키를 기준으로 묶어서 사용되지만, KTable로 선언된 토픽은 1개 파티션이 1개 태스크에 할당되어 사용되고, GlobalKTable로 선언된 토픽은 모든 파티션 데이터가 각 태스크에 할당되어 사용된다는 차이점이 있다.
- KStream과 KTable이 조인을 할 때 코파티셔닝(co-partitioning)이 되어 있어야 하는데, 코파티셔닝되지 않은 KStream과 KTable을 조인해서 사용하고 싶다면 KTable을 GlobalKTable로 선언하여 사용할 수 있다.

![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%203.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/c75de212-db57-4253-af44-a4ae3329215b/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T081944Z&X-Amz-Expires=86400&X-Amz-Signature=c5d9c87643dedda492ac7f6658e92346bd8b79c4a1cd3593db5125a5ee3e256d&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

### 스트림즈DSL 주요 옵션

- 필수 옵션
    - bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름:포트 1개 이상 작성
    - application.id: 스트림즈 애플리케이션 고유 id
- 선택 옵션
    - default.key.serde: 레코드의 메시지 키를 직렬화, 역직렬화하는 클래스 지정. 기본값은 Serdes.ByteArray().getClass().getName()
    - default.value.serde: 레코드의 메시지 값을 직렬화, 역직렬화하는 클래스를 지정. 기본값은 Serdes.ByteArray().getClass().getName()
    - num.stream.threads: 스트림 프로세싱 실행 시 실행될 스레드 개수 지정. 기본값은 1.
    - state.dir: 상태기반 데이터 처리를 할 때 데이터를 저장할 디렉토리 지정. 기본값은 /tmp/kafka-streams

### 스트림즈DSL - stream(), to()

- stream(): 특정 토픽을 KStream 형태로 가져올 때 사용
- to(): KStream 데이터를 특정 토픽으로 저장할 때 사용

![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%204.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b5da0e81-1793-4392-850f-882a2e0cfc11/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T081950Z&X-Amz-Expires=86400&X-Amz-Signature=bd461c29b06bfd1e97d4f15617a4eb9c239d5b20861640c0c9d38e8623d6f84c&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

### 스트림즈DSL - filter()

- filter(): 메시지 키 또는 메시지 값을 필터링하여 특정 조건에 맞는 데이터를 골라낼 때 사용

![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%205.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7f9287b2-ce6a-4cd8-aadc-1f8180123728/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T081955Z&X-Amz-Expires=86400&X-Amz-Signature=afa480b6fe563c0895182b236ebbf4d9e901c6484746f8640fd5d89250d23c85&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

### 스트림즈DSL - KTable과 KStream을 join()

- KTable과 KStream을 함께 사용하는 경우, 메시지 키를 기준으로 조인
- 실시간으로 들어오는 데이터들 조인 가능
- 코파티셔닝 여부 확인 필수 (동일한 파티션 개수, 동일한 파티셔닝)

![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%206.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/1ee554e3-6f25-438e-adc7-7477ceff7013/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T082000Z&X-Amz-Expires=86400&X-Amz-Signature=4d26a15501c50bcbfce4592f8738bc0962a0c24870b637b04f50e13db9296d20&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

### 스트림즈DSL - GlobalKTable과 KStream을 join()

- 코파티셔닝되어 있지 않은 토픽을 조인해야 할 때, KTable로 사용하는 토픽을 GlobalKTable로 선언하여 사용

![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%207.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/c3980b62-cda9-4144-b89f-f1307a8d4c66/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T082004Z&X-Amz-Expires=86400&X-Amz-Signature=35e668d80e0f8d1e21231e31b4595789aa3874dc63dd31b7e7f035286a0a9581&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

## 3.5.2 프로세서 API

- 스트림즈DSL은 데이터 처리, 분기, 조인을 위한 다양한 메서드들을 제공하지만 추가적인 상세 로직의 구현이 필요하다면 프로세서 API를 활용할 수 있다.
- KStream, KTable, GlobalKTable 개념이 없다.

# 3.6 카프카 커넥트

- 카프카 오픈소스에 포함된 툴 중 하나로 데이터 파이프라인 생성 시 반복 작업을 줄이고 효율적인 전송을 이루기 위한 애플리케이션
- 반복적인 파이프라인 생성 작업이 있을 때, 매번 프로듀서, 컨슈머 애플리케이션을 개발하고 배포, 운영하는 대신 특정 작업 형태를 템플릿으로 만들어 놓은 커텍터(connector)를 실행함으로써 반복 작업을 줄일 수 있다.
- 파이프라인 생성 시 자주 반복되는 값들(토픽 이름, 파일 이름, 테이블 이름 등)을 파라미터로 받는 커넥터를 코드로 작성하면 이후 파이프라인을 실행할 때는 코드를 작성할 필요가 없다.
- 커넥터는 각 커넥터가 가진 고유한 설정값을 입력 받아 데이터를 처리한다.
- 커넥터의 종류
    1. 소스 커넥터
        - 프로듀서 역할, 데이터를 카프카 토픽으로 전송
    2. 싱크 커넥터
        - 컨슈머 역할, 토픽의 데이터를 저장

    ![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%208.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a9a945c6-bdaa-4369-93ae-93165fe29ee0/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T082009Z&X-Amz-Expires=86400&X-Amz-Signature=8cc4d69c610054f6f3a759182ad0165ba94bad15e95b99eae592c061e82a1307&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

    +

    - 미러메이커2 커넥터 → 클러스터 간 토픽 미러링 지원
    - 파일 싱크 커넥터, 파일 소스 커넥터
    - 이외에 추가적인 커넥터를 사용하고 싶다면 플러그인 형태로 커넥터 jar파일을 추가하여 사용할 수 있다. (커넥터 jar파일 → 커넥터를 구현하는 클래스를 빌드한 클래스 파일 포함)
    - 오픈소스 커넥터 → [컨플루언트 허브](https://www.confluent.io/hub/)
- 커넥트 생성 명령을 내리면 커넥트는 내부에 커텍터와 태스크를 생성한다.
    - 커넥트는 태스크들을 관리한다.
    - 태스크는 실질적인 데이터 처리를 한다.

![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%209.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/1407bb5d-d40d-4693-af7b-3fed5c8df2b1/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T082015Z&X-Amz-Expires=86400&X-Amz-Signature=1c563acf6255b2305a5378ee000df7332e8f2eb0d6f487e0855b03f8edf41a8c&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- 커넥터를 사용하여 파이프라인을 생성할 때 컨버터(converter)와 트랜스폼(transform) 기능을 옵션으로 추가할 수 있다.
    - 컨퍼터: 데이터 처리 전 스키마를 변경하도록 도와준다
    - 트랜스폼: 데이터 처리 시 각 메시지 단위로 데이터를 간단하게 변환하기 위한 용도로 사용된다

### 커넥트를 실행하는 방법

1. 단일 모드 커넥트 (standalone mode kafka connect)
    - 단일 어플리케이션으로 실행된다.
    - 커넥트를 정의하는 파일을 작성하고 해당 파일을 참조하는 단일 모드 커넥트를 실행함으로써 파이프라인을 생성할 수 있다.
    - 1개 프로세스만 실행 → 고가용성 구성이 되지 않아 단일 장애점(SPOF)이 될 수 있다.
    - 개발환경이나 중요도가 낮은 파이프라인 운영 시 사용

    ![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%2010.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/450f3701-fa75-45b9-956e-78e7d4877f82/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T082019Z&X-Amz-Expires=86400&X-Amz-Signature=cf3a19eae18136dd7df1335df9a21e879772057a6be7747714aaeca93a335b64&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

2. 분산 모드 커넥트 (distributed mode kafka connect)
    - 2대 이상의 서버에서 클러스터 형태로 운영함으로써 단일 모드 커넥트 대비 안전하게 운영할 수 있다.
    - 데이터 처리량의 변화에도 유연하게 대응할 수 있다 → 스케일 아웃 가능

    ![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%2011.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a976663d-3e6b-4010-9cd4-9e804bedd3ae/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T082024Z&X-Amz-Expires=86400&X-Amz-Signature=61938a3ac1fba5c50fb94015d6db0d1934ff78e612655ced02e802763be81066&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- 카프카 커넥트 REST API (표3.6-1)

### 단일 모드 커넥트

1. config/connect-standalone.properties 파일 수정 (커넥트 파일)
2. config/connect-file-source.properties 파일 정의 (커넥터 파일)
3. 단일 모드 커넥트 실행

    ```bash
    $ bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties
    ```

### 분산 모드 커넥트

1. config/connect-distributed.properties 파일 설정 (분산 모드 설정 파일, 커넥트 파일)
2. 분산 모드 커넥트 실행

    ```bash
    $ bin/connect-distributed.sh config/connect-distributed.properties
    ```

3. 분산 모드 커넥트가 실행되고 난 이후 REST API로 커넥트의 상태, 커넥터 생성, 커넥터 조회, 커넥터 수정, 커넥터 중단 등 명령을 날릴 수 있다.

## 3.6.1 소스 커넥터

![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%2012.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/9527fca7-f03e-4fa0-bb89-1789b5a1fc36/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T082029Z&X-Amz-Expires=86400&X-Amz-Signature=0f953c6dfcf14d3cad95fb28826072759da0e639e64a9e66e2c946d3a3dd81a9&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- 소스 애플리케이션 또는 소스 파일로부터 데이터를 가져와 토픽으로 넣는 역할을 한다.
- SourceConnector와 SourceTask 클래스를 사용하여 직접 소스 커넥터를 구현할 수 있다.
- 직접 구현한 소스 커넥터를 빌드하여 jar 파일로 만들고 커넥트를 실행 시 플러그인으로 추가하여 사용할 수 있다.
- 소스 커넥터를 만들 때는 connect-api 라이브러리(커넥터 개발을 위한 클래스들)를 추가해야 한다. build.gradle에 다음과 같이 디펜던시를 추가한다.

```bash
dependencies {
	compile 'org.apache.kafka:connect-api:2.5.0'
}
```

- SourceConnector → 태스크를 실행하기 전 커넥터 설정 파일을 초기화하고 어떤 태스크 클래스를 사용할 것인지 정의
- SourceTask → 실제로 데이터를 다루는 클래서. 소스 애플리케이션 또는 소스 파일로부터 데이터를 가져와서 토픽으로 데이터를 보내는 역할. 소스 애플리케이션 또는 소스 파일을 어디까지 읽었는지 저장하는 오프셋을 사용한다.

## 3.6.2 싱크 커넥터

![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%2013.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d08b00ab-9c80-4c64-8155-3ee371bddb84/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T082033Z&X-Amz-Expires=86400&X-Amz-Signature=dcba505a8344c737492fd3739fb6bc69d602004e2bf79ca7dd346ec96429b5e7&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- 토픽의 데이터를 타깃 애플리케이션 또는 타깃 파일로 저장하는 역할을 한다.
- 카프카 커넥트 라이브러리에서 제공하는 SinkConnector와 SinkTask 클래스를 사용하면 직접 싱크 커넥터를 구현할 수 있다.
- 직접 구현한 싱크 커넥트는 빌드하여 jar 파일로 만들고 커넥트의 플러그인으로 추가하여 사용할 수 있다.
- 싱크 커넥터를 만들 때 connect-api 라이브러리(커넥터 개발을 위한 클래스들)를 추가해야 한다. build.gradle에 다음과 같이 디펜던시를 추가한다.

```bash
dependencies {
	compile 'org.apache.kafka:connect-api:2.5.0'
}
```

- SinkConnector → 태스크를 실행하기 전 사용자로부터 입력 받은 설정 값을 초기화하고 어떤 태스크 클래스를 사용할 것인지 정의
- SinkTask → 실제로 데이터를 처리. 커넥트에서 컨슈머 역할을 하고 데이터를 저장하는 코드를 갖는다.

# 3.7 카프카 미러메이커2

![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%2014.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/9d91448d-558a-432c-8589-42d8f3d337d9/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T082038Z&X-Amz-Expires=86400&X-Amz-Signature=33db2b0b9c559c3cd4c59309ea6ad8fe6eb8c532197d075880ce887cb01d2955&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- 서로 다른 두 개의 카프카 클러스터 간에 토픽을 복제하는 애플리케이션
- 토픽의 데이터를 완전히 동일하기 옮기기 위해 사용
- 미러메이커1: 레거시 버전. 최초의 토픽 데이터 복제 기능을 가진 애플리케이션.
    - 단점
        - 기본 파티셔너를 사용하여 복제 전 데이터와 복제 후 데이터의 파티션 정보가 다름
        - 복제하는 토픽이 달라지면 수정하기 위해 미러메이커 애플리케이션 재시작해야 함
        - exactly one delivery를 보장하지 못하여 복제하는 데이터의 유실 또는 중복 발생 가능성 존재
        - 카프카 클러스터의 양방향 토픽 복제 지원 X
    - 미러메이커2 → 위의 단점 해소
        - 토픽 데이터 복제 뿐 아니라 토픽 설정까지도 복제하여 파티션의 변화, 토픽 설정값의 변화도 동기화하는 기능을 가진다
        - 커넥터 사용도 가능

    ### 미러메이커2를 활용한 단방향 토픽 복제

    - config/connect-mirror-maker.properties 파일 수정

    예) 카프카 클러스터 A와 카프카 클러스터 B가 있을 경우, 클러스터 A에 존재하는 test라는 이름의 토픽을 클러스터 B로 복제

    ```bash
    clusters = A, B # 복제할 클러스터의 닉네임

    # 미러메이커2에서 사용할 클러스터의 접속 정보
    A.bootstrap.servers = a-kafka:9092 
    B.bootstrap.servers = b-kafka:9092

    # 클러스터A에서 클러스터B로 복제를 진행할 것인지, 어떤 토픽을 복제할 것인지 명시
    A->B.enabled = true
    A->B.topics = test

    # 양방향 토픽 복제 가능, 여기서는 단방향이므로 false
    B->A.enabled = false
    B->A.topics = .*

    # 복제되어 신규 생성된 토픽의 복제 개수 설정
    replication.factor=1

    # 토픽 복제에 필요한 데이터를 저장하는 내부 토픽의 복제 개수 설정
    checkpoints.topic.replication.factor=1
    heartbeats.topic.replication.factor=1
    offset-syncs.topic.replication.factor=1
    offset.storage.replication.factor=1
    status.storage.replication.factor=1
    config.storage.replication.factor=1
    ```

    - 설정이 완료되면 다음과 같은 명령어로 설정 파일과 함께 실행

    ```bash
    $ bin/connect-mirror-maker.sh config/connect-mirror-maker.properties
    ```

- 실행 이후 클러스터 A의 test 토픽에 데이터를 넣으면, 클러스터 B의 A.test 토픽에 정상적으로 복제되는 것을 알 수 있다.
- 파티션 동기화 역시 가능하다

## 3.7.1 미러메이커2를 활용한 지리적 복제(Geo-Replication)

- 카프카 클러스터 단위의 활용도를 높일 수 있다
- 단방향, 양방향 복제 기능, ACL 복제, 새 토픽 자동 감지 기능 등

### 액티브-스탠바이(Active-stanby) 클러스터 운영

![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%2015.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f5c053dc-52e0-4ef1-b705-9058b2854a78/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T082045Z&X-Amz-Expires=86400&X-Amz-Signature=7d827b89065bb40fb5d06cf6952bab50b9d2c825043169fafc022322dd66224f&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- 재해 복구를 위해 임시 카프카 클러스터를 하나 더 구성하는 경우 액티브-스탠바이 클러스터로 운영할 수 있다.
- '액티브 클러스터' → 서비스 애플리케이션들이 직접 통신하는 카프카 클러스터
- '스탠바이 클러스터' → 임시 클러스터. 액티브 클러스터와 물리적인 구역을 분리하여 운영.
- 클러스터에 재해가 생기는 경우
    1. 자연 재해(홍수, 허리케인, 지진)
    2. 기술적 재해(EMP 공격, 데이터센터의 중단 등)
    3. 인간에 의한 재해(사이버 공격, 사보타주 등) 

### 액티브-액티브(Active-active) 클러스터 운영

![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%2016.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/27853d91-c8e0-4bec-8a41-4bcc9323550b/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T082050Z&X-Amz-Expires=86400&X-Amz-Signature=6e3b97577fa14624e81dea5275d6a906e1b71be1c8fa0d35b9f0c710b4e38ac9&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- 글로벌 서비스를 운영할 경우 서비스 애플리케이션의 통신 지연을 최소화하기 위해 2개 이상의 클러스터를 두고 서로 데이터를 미러링하면서 사용할 수 있는데, 이 때 액티브-액티브 클러스터를 운영할 수 있다.
- 각 지역마다 클러스터를 두고 필요한 데이터만 복제하여 사용하는 방법

### 허브 앤 스포크(Hub and spoke) 클러스터 운영

![%5B3%E1%84%8C%E1%85%A1%E1%86%BC%5D%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC(2)%202d3c5f15b21f47cbb261c39aff277383/Untitled%2017.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/bbee2d83-6a66-419f-9831-7697c2cd04e9/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210808%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210808T082054Z&X-Amz-Expires=86400&X-Amz-Signature=9bc20ee75f9baa7b067e0f1d1f68eff60ddbe58f1444b63652ab306e4a70cec4&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- 각 팀에서 소규모 카프카 클러스터를 사용하고 있을 때 각 팀의 카프카 클러스터의 데이터를 한 개의 카프카 클러스터에 모아 데이터 레이크로 사용하고 싶다면 허브 앤 스포크 방식의 클러스터를 운영할 수 있다.
- 허브 → 중앙에 위치한 데이터 레이크 용도의 카프카 클러스터. 데이터 수집, 가공, 분석.