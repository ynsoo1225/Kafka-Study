# [1장] 들어가며

# 1.1 카프카의 탄생

- 내부 데이터 흐름을 개선하기 위해 개발
- 각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라 한 곳에 모아 처리할 수 있도록 **중앙집중화**했다.
- 데이터 스트림을 한 곳에서 실시간으로 관리할 수 있게 해준다.
- 기업의 대용량 데이터를 수집하고 이를 사용자들이 실시간 스트림으로 소비할 수 있게 만들어준다.
- 카프카를 중앙에 배치함으로써 소스 애플리케이션과 타깃 애플리케이션 사이의 의존도를 최소화하여 커플링을 완화하였다.
- 소스 애플리케이션에서 생성되는 데이터를 일단 카프카로 넣으면 된다.

![1](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/c7590300-ece9-4ce6-93c5-16bd38edb029/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210718%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210718T104405Z&X-Amz-Expires=86400&X-Amz-Signature=ba853ba304a71812b2e2961845a1390d7ff0a58cb759d62b01e6a1900bba29b0&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

![2](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/370ee9de-5b72-422b-8b17-0fee0b9172a8/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210718%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210718T104412Z&X-Amz-Expires=86400&X-Amz-Signature=4a5297e5dbc483a24221e26e5555c41765064a7cad518ddcc1263a37e0c83447&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- 카프카 내부에 데이터가 저장되는 파티션의 동작은 FIFO 방식의 큐 자료구조와 유사하다.
- 큐에 데이터를 보내는 것이 **프로듀서**이고 데이터를 가져가는 것이 **컨슈머**이다.

![3](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6a3ad690-03f3-46f5-98d6-6a1ead2c4ace/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210718%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210718T104419Z&X-Amz-Expires=86400&X-Amz-Signature=274700979ceffdef65e32434a66ee0bebc4f32a9153b3acdb1fe28be4e51f780&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- 데이터 포맷은 사실상 제한이 없으며 직렬화, 역직렬화를 통해 ByteArray로 통신하기 때문에 자바에서 선언 가능한 모든 객체를 지원한다.
- 카프카는 최소 3대 이상의 서버(브로커)에서 분산 운영하여 프로듀서를 통해 전송받은 데이터를 파일 시스템에 안전하게 기록한다. 서버 3대 이상으로 이루어진 카프카 클러스터 중 일부 서버에 장애가 발생하더라도 데이터를 지속적으로 복제하기 때문에 안전하게 운영할 수 있다.
- 또한, 데이터를 묶음 단위로 처리하는 배치 전송을 통해 낮은 지연과 높은 데이터 처리량도 가지게 되었다.
- 엄청난 양의 데이터를 안전하고 빠르게 처리하는 강점

# 1.2 빅데이터 파이프라인에서 카프카의 역할

- **데이터 레이크 (data lake)**
    - 빅데이터를 저장하고 활용하기 위해 일단 생성되는 데이터를 모두 모으는 것
    - 데이터 웨어하우스와 다르게 필터링되거나 패키지화되지 않은 데이터가 저장된다.
    - 운영되는 서비스로부터 수집 가능한 모든 데이터를 모으는 것이다.
    - 엔드 투 엔드 방식
    - 하지만 점점 서비스가 비대해지고 복잡해지면서 파편화되고 올라가는 문제점이 발생한다.
- **데이터 파이프라인**
    - 위의 문제점을 해결하기 위해 데이터 추출(extracting), 변경(transforming), 적재(loading)하는 과정을 묶은 것
    - 엔드 투 앤드 방식의 데이터 수집 및 적재를 개선하고 안정성을 추구하며, 유연하면서도 확장 가능하게 자동화하였다.

## 아파치 카프카가 왜 데이터 파이프라인으로 적합한가?

### 높은 처리량

- 동일한 양의 데이터를 보낼 때 네트워크 통신 횟수를 최소한으로 줄인다면 동일 시간 내에 더 많은 데이터를 전송할 수 있다.
- 많은 양의 데이터를 묶음 단위로 처리하는 배치로 빠르게 처리할 수 있기 때문에 대용량의 실시간 로그데이터를 처리하는 데에 적합하다.
- 또한, 파티션 단위를 통해 동일 목적의 데이터를 여러 파티션에 분배하고 데이터를 병렬 처리할 수 있다.
- 파티션 개수만큼 컨슈머 개수를 늘려서 동일 시간당 데이터 처리량을 늘리는 것이다.

### 확장성

- 가변적인 환경에서 안정적으로 확장 가능하도록 설계되었다.
- 브로커의 개수를 늘리고 줄이는 스케일 아웃, 스케일 인이 가능하다.

### 영속성

- 생성한 프로그램이 종료되더라도 사라지지 않는 데이터의 특성
- 전송 받은 데이터를 메모리에 저장하지 않고 파일 시스템에 저장한다.
- 페이지 캐시 영역을 메모리에 따로 생성하여 사용한다.
- 캐시 메모리 영역을 사용하여 한 번 읽은 파일 니용은 메모리에 저장시켰다가 다시 사용하는 방식이기 때문에 카프카가 파일 시스템에 저장하고 데이터를 저장, 전송하더라도 처리량이 높다.

### 고가용성

- 3개 이상의 서버들로 운영되는 카프카 클러스터는 일부 서버에 장애가 발생하더라도 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있다
- 클러스터로 이루어진 카프카는 데이터의 복제를 통해 고가용성의 특징을 갖는다.
- 프로듀서로 전송 받은 데이터를 여러 브로커에 저장하는 것이다.

❓ **카프카 클러스터를 3대 이상의 브로커들로 구성해야 하는 이유**

카프카를 안전하게 운영하기 위해 최소 3대 이상의 브로커로 클러스터를 구성할 것을 추천한다. 

1대 → 브로커의 장애가 서비스의 장애로 이어지므로 테스트 목적으로만 사용한다.

2대 → 한 대의 브로커에 장애가 발생하더라도 나머지 한 대 브로커가 살아 있으므로 안정적인 데이터 처리가 가능하다. 하지만 브로커 간 데이터가 복제되는 시간 차이로 인해 일부 데이터가 유실될 가능성이 있다. 

유실을 막기 위해 min.insync.replicas 옵션을 2로 설정하면 최소 2개 이상의 브로커에 데이터가 완전히 복제됨을 보장하며, 이 때 브로커를 3대 이상으로 운영해야만 한다. 3개 중 1개의 브로커에 장애가 나더라도 지속적으로 데이터를 처리할 수 있기 때문이다. 

![4](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/cc21ea8b-a82b-4884-9450-d06bf96dc0b7/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210718%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210718T104427Z&X-Amz-Expires=86400&X-Amz-Signature=57f761adde9c61bf1f3b207cd2be599ab2199d8fef2a55635322fe100737f18c&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

# 1.3 데이터 레이크 아키텍처와 카프카의 미래

**데이터 레이크 아키텍처의 종류**

1. 람다 아키텍처
2. 카파 아키텍처

### 람다 아키텍처

- 데이터를 배치 처리하는 레이어와 실시간 처리하는 레이어를 분리한다.
- 단점
    1. 데이터를 분석, 처리하는 데 필요한 로직이 2벌로 각각의 레이어에 따로 존재해야 한다는 점
    2. 배치 데이터와 실시간 데이터를 융합하여 처리할 때는 다소 유연하지 못한 파이프라인을 생성해야 한다는 점

### 카파 아키텍처

![5](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d92c5232-949d-490c-9f4c-0784fd529518/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210718%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210718T104432Z&X-Amz-Expires=86400&X-Amz-Signature=19d84c188320677234ea7daadd1d4add44407218ac9f6c2b7a5a501112d7a42e&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- 배치 레이어를 제거하고 모든 데이터를 스피드 레이어에 넣어서 처리
- 로직의 파편화, 디버깅, 배포, 운영 분리에 대한 이슈를 제고하기 위해 배치 레이어 제거
- 스피드 레이어에서 데이터를 모두 처리할 수 있어 더욱 효율적인 개발과 운영을 가능하게 하였다.
- 생성되는 모든 종류의 데이터를 스트림 처리해야 한다. → 모든 데이터를 로그(log)로 바라보기!
- 이 데이터는 지속적으로 추가가 가능하며 각 데이터에는 일정한 번호(또는 타임스탬프)가 붙는다.
- 로그는 배치 데이터를 스트림으로 표현하기에 적합하다.

![6](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/54ba29f2-ea3a-4b18-82ac-6e66223f78cb/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210718%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210718T104441Z&X-Amz-Expires=86400&X-Amz-Signature=5209587a44c9378afd680947971a14a3d1d830d5698accd172a1e3be5698c368&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

![7](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/518bed6e-1c61-4f9c-8664-3c65c6bdd860/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210718%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210718T104445Z&X-Amz-Expires=86400&X-Amz-Signature=89a9c509a0ffbae9e08b060be7b828ee57b379c5c7b808409c70d295b65d53a6&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- 카파 아키텍처는 스트림 데이터를 서빙 레이어(=저장소)에 저장한다.
- 스피드 레이어로 사용되는 카프카에 분석과 프로세싱을 완료한 거대한 용량의 데이터를 오랜 기간 저장하고 사용할 수 있다면 서빙 레이어는 제거되어도 된다. → 스피드 레이어에서 데이터를 분석, 프로세싱, 저장함으로써 단일 진실 공급원(SSOT)이 되는 것이다.

![8](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/703aaf48-d6ff-4fac-85f8-7c5a909e64f0/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210718%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210718T104450Z&X-Amz-Expires=86400&X-Amz-Signature=e6bafa03b955603a9848e88ac1c9104928eb8592d851047ad0ab7aa95bce28d4&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

❓ **배치 데이터와 스트림 데이터**

'**배치 데이터**'는 초, 분, 시간, 일 등으로 한정된 기간 단위 데이터를 뜻하며,  일괄 처리하는 것이 특징이다. 

'**스트림 데이터**'는 한정되지 않은 데이터로 시작 데이터와 끝 데이터가 명확히 정해지지 않은 데이터를 뜻한다. 각 지점의 데이터는 보통 작은 단위(KB 단위)로 쪼개져 있으며 웹 사용자의 클릭 로그, 주식 정보, 사물 인터넷의 센서 데이터를 스트림 데이터라고 볼 수 있다.

### 개선해야 하는 부분

- 자주 접근하지 않는 데이터는 오브젝트 스토리지와 같이 저렴하면서도 안전한 저장소에 옮겨 저장하고 자주 사용하는 데이터만 브로커에서 사용하는 구분 작엽이 필요하다 → 단계별 저장소
- 카프카의 데이터를 쿼리할 수 있는 주변 데이터 플랫폼이 필요하다 → ksqlDB