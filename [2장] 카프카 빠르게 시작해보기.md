# [2장] 카프카 빠르게 시작해보기

# 2.1 실습용 카프카 브로커 설치

## 2.1.1 AWS EC2 인스턴스 발급 및 보안 설정

**AWS에서 카프카 구축할 수 있는 방법**

1. MSK
2. EC2

여기서는 EC2 인스턴스를 사용하는 과정으로 진행한다.

## 2.1.2 인스턴스에 접속하기

```bash
[EC2 인스턴스]
$ ssh -i '{pem key 이름}.pem' ec2-user@{ip 주소}
```

## 2.1.3 인스턴스에 자바 설치

```bash
[EC2 인스턴스]
$ sudo yum install -y java-1.8.0-openjdk-devel.x86_64
$ java -version
```

## 2.1.4 주키퍼, 카프카 브로커 실행

```bash
[EC2 인스턴스]
$ wget https://archive.apache.org/dist/kafka/2.5.0/kafka_2.12-2.5.0.tgz
$ tar xvf kafka_2.12-2.5.0.tgz
$ ll
$ cd kafka_2.12-2.5.0

# 카프카 브로커 힙 메모리 설정
$ export KAFKA_HEAP_OPTS="Xmx400m -Xms400m"
$ echo $KAFKA_HEAP_OPTS

# 환경변수 설정해두기
$ vi ~/.bashrc
...
# User specific aliases and functions
export KAFKA_HEAP_OPTS="Xmx400m -Xms400m"
$ source ~/.bashrc
$ echo $KAFKA_HEAP_OPTS
$ cat bin/kafka-server-start.sh

# 카프카 브로커 실행 옵션 설정
$ vi config/server.properties
(여기서 브로커 실행 옵션을 확인 및 설정할 수 있다.)

# 주키퍼 실행
$ bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
$ jps -vm

# 카프카 브로커 실행 및 로그 확인
$ bin/kafka-server-start.sh -daemon config/server.properties
$ jps -m
$ tail -f logs/server.log
```

## 2.1.5 로컬 컴퓨터에서 카프카와 통신 확인

```bash
[로컬]
$ curl https://archive.apache.org/dist/kafka/2.5.0/kafka_2.12-2.5.0.tgz --output kafka.tgz
$ tar -xvf kafka.tgz
$ cd kafka_2.12-2.5.0
$ ls
$ ls bin
$ bin/kafka-broker-api-versions.sh --bootstrap-server {브로커 ip 주소}:9092

# 테스트 편의를 위한 hosts 설정
$ vi /etc/hosts
{브로커 ip 주소} my-kafka
```

# 2.2 카프카 커맨드 라인 툴

## 2.2.1 kafka-topics.sh

### 토픽 생성

```bash
[로컬]
$ bin/kafka-topics.sh \
	--create \ # 1
	--bootstrap-server my-kafka:9092 \ # 2
	--topic hello.kafka # 3
Created topic hello.kafka.
```

1. 토픽 생성 명령어
2. 토픽을 생성할 카프카 클러스터를 구성하는 브로커들의 IP와 port를 적는다
3. 토픽 이름 작성

```bash
[로컬]
$ bin/kafka-topics.sh \
	--create \
	--bootstrap-server my-kafka:9092 \
	--partitions 3 \ # 1
	--replication-factor 1 \ # 2
	--config retention.ms=172800000 \ # 3
	--topic hello.kafka.2
Created topic hello.kafka.2
```

1. 파티션 개수 지정
2. 토픽의 파티션을 복제할 목제 개수
3. [kafka-topics.sh](http://kafka-topics.sh) 명령에 포함되지 않은 추가적인 설정을 할 수 있다. *[retention.ms](http://retention.ms) → 토픽의 데이터를 유지하는 기간

### 토픽 리스트 조회

```bash
[로컬]
$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --list
hello.kafka
hello.kafka.2
```

### 토픽 상세 조회

```bash
[로컬]
$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --describe --topic hello.kafka.2
```

### 토픽 옵션 수정

```bash
[로컬]
$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 \
	--topic hello.kafka \ 
	--alter \ 
	--partitions 4 # 1

$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 \
	--topic hello.kafka \ 
	--describe # 변경 내용 확인

$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 \
	--entity-type topics \ 
	--entity-name hello.kafka \ 
	--alter --add-config retention.ms=86400000 # 2

$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 \
	--entity-type topics \ 
	--entity-name hello.kafka \ 
	--describe # 변경 내용 확인
```

1. 파티션 개수 변경
    1. 파티션을 늘릴 수는 있지만 줄일 수는 없다
    2. 파티션 번호는 0부터 시작하고 1씩 늘어난다
2. [retention.ms](http://retention.ms) 수정

## 2.2.2 kafka-console-producer.sh

토픽에 넣는 데이터는 '레코드(record)'라고 부르며 메시지 키(key)와 메시지 값(value)로 이루어져 있다.

```bash
[로컬]
# 메시지 값만 보내기 (메시지 키는 null)
$ bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
	--topic hello.kafka
>hello
>kafka
>0
>1
>2
>3
>4
>5

# 메시지 키를 갖는 레코드 전송
$ bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
	--topic hello.kafka \
	--property "parse.key=true" \ # 1
	--property "key.separator=:" # 2
>key1:no1
>key2:no2
>key3:no3
```

1. parse.key를 true로 두면 레코드를 전송할 때 키를 추가할 수 있다.
2. 메시지 키와 메시지 값을 구분하는 구분자를 선언한다. *default=\t
- 메시지 키와 메시지 값을 함께 전송한 레코드는 토픽의 파티션에 저장된다.
- 메시지 키가 null인 경우에는 프로듀서가 파티션으로 전송할 때 레코드 배치 단위로 라운드 로빈으로 전송한다.
- 메시지 키가 존재하는 경우에는 키의 해시값을 작성하여 존재하는 파티션 중 한 개에 할당된다. → 메시지 키가 동일할 경우 동일 파티션에 전송
- 커스텀 파티셔너를 사용할 경우에는 메시지 키에 따른 파티셔 할당이 다르게 동작할 수도 있다.

## 2.2.3 kafka-console-consumer.sh

토픽으로 전송한 데이터를 확인할 수 있는 명령어. 

**필수옵션**

- --bootstrap-server: 카프카 클러스터 정보
- --topic: 토픽 이름
- --from-beginning: 토픽에 저장된 가장 처음 데이터부터 출력

```bash
[로컬]
$ bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 \
	--topic hello.kafka \
	--from-beginning

$ bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 \
	--topic hello.kafka \
	--property print.key=true \ # 1
	--property key.separator="-" \ # 2
	--group hello-group \ # 3
	--from-beginning
```

1. 메시지 키 확인
2. 메시지 키 값 구분
3. 신규 컨슈머 그룹 생성

## 2.2.4 kafka-consumer-groups.sh

컨슈머 그룹으로 생성된 컨슈머로 토픽의 데이터를 가져간다. 

```bash
[로컬]
$ bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --list
hello-group

$ bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092
	--group hello-group \ 
	--describe
```

1. --group: 컨슈머 그룹 선택
2. --describe: 컨슈머 그룹 상세 내용 확인

## 2.2.5 kafka-verifiable-producer, consumer.sh

String 타입 메시지 값을 코드 없이 주고 받는 명령어.

카프카 클러스터 설치가 완료된 이후에 토픽에 데이터를 전송하여 간단한 네트워크 통신 테스트를 할 때 유용하다.

```bash
[로컬]
$ bin/kafka-verifiable-producer.sh --bootstrap-server my-kafka:9092 \
	--max-messages 10 \
	--topic verify-test

$ bin/kafka-verifiable-consumer.sh --bootstrap-server my-kafka:9092 \
	--topic verify-test \
	--group-id test-group
```

## 2.2.6 kafka-delete-records.sh

적재된 토픽의 데이터를 지우는 명령어.

가장 오래된 데이터(가장 낮은 숫자의 오프셋)부터 특정 시점의 오프셋까지 삭제할 수 있다.

```bash
[로컬]
# 삭제하고자 하는 데이터에 대한 정보를 파일로 저장해서 사용해야 한다
$ vi delete-topic.json
{"partitions": [{"topic": "test", "partition": 0, "offset": 50}], "version": 1 }

$ bin/kafka-delete-records.sh --bootstrap-server my-kafka:9092 \
	--offset-json-file delete-topic.json
```