# [3장] 카프카 기본 개념 설명(1)

**실습 과정 예제 코드**: [https://github.com/bjpublic/apache-kafka-with-java](https://github.com/bjpublic/apache-kafka-with-java) 

# 3.1 카프카 브로커 / 클러스터 / 주키퍼

## 브로커

- 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체이자, 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션
- 하나의 서버 → 한 개의 카프카 브로커 프로세스
- 안전한 데이터 보관 및 처리를 위해 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영

### 주요 역할

1. **데이터 저장, 전송**
    - 프로듀서로부터 데이터를 전달 받으면 카프카 브로커는 프로듀서가 요청한 토픽의 파티션에 데이터를 저장하고, 컨슈머가 데이터를 요청하면 파티션에 저장된 데이터를 전달한다.
2. **데이터 복제, 싱크**
    - 카프카의 데이터 복제는 파티션 단위로 이루어진다.
    - 복제된 파티션은 리더와 팔로워로 구성된다. 프로듀서 또는 컨슈머와 직접 통신하는 파티션을 리더, 나머지 복제 데이터를 가지고 있는 파티션을 팔로워라고 부른다.
    - 팔로워 파티션들은 리더 파티션의 오프셋을 확인하여 현재 자신이 가지고 있는 오프셋과 차이가 나는 경우 리더 파티션으로부터 데이터를 가져와서 자신의 파티션에 저장한다. → **복제**

    ![1](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b8a2c237-8be5-423f-ac84-c220c8e1c8e4/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210724%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210724T124236Z&X-Amz-Expires=86400&X-Amz-Signature=215108dbd461eac0918f23822ba7d208a4135f2e914ce774157b8352ebf7e0f5&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

    ![2](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/00445053-1da6-49f1-b2f2-7094e4692698/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210724%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210724T124240Z&X-Amz-Expires=86400&X-Amz-Signature=c39e04f60010898fa1ea3d07fd5bc7014cabf6889a1098f735f286a90217fe78&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

3. **컨트롤러**
    - 클러스터의 다수 브로커 중 한 대가 컨트롤러의 역할을 한다.
    - 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배한다.
4. **데이터 삭제**
    - 카프카는 오직 브로커만이 데이터를 삭제할 수 있다.
    - 데이터 삭제는 파일 단위로 이루어지는데 이 단위를 '로그 세그먼트(log segment)'라고 부른다.
    - 세그먼트는 데이터가 쌓이는 동안 파일 시스템으로 열려있으며 카프카 브로커에 `log.segment.bytes` 또는 `log.segment.ms` 옵션에 값이 설정되면 세그면트 파일이 닫힌다.
5. **컨슈머 오프셋 저장**
    - 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋한다.
    - 커밋한 오프셋은 __consumer_offsets 토픽에 저장한다.
6. **코디네이터**
    - 클러스터의 다수 브로커 중 한 대는 코디네이터의 역할을 수행한다.
    - 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 한다.
    - 파티션을 컨슈머로 재할당한다 → '리밸런스'

## 주키퍼

- 카프카의 메타데이터를 관리
- 주키퍼 쉘 명령어는 zookeeper-shell.sh로 실행할 수 있으며 bin 폴더 안에 있다.

```bash
$ bin/zookeeper-shell.sh my-kafka:2181

# 주키퍼 명령어
ls / # root znode의 하위 znode들을 확인
get /brokers/ids/0 # 카프카 브로커에 대한 정보 확인
get /controller # 어느 브로커가 컨트롤러인지
ls /brokers/topics # 카프카에 저장된 토픽들 확인
```

![3](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/edf7d1e9-d6ab-4484-8ba4-caa4c6a4e582/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210724%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210724T124245Z&X-Amz-Expires=86400&X-Amz-Signature=d9768bf96d7f72b644b07dba92b3d58f58e5f871135979d60210eca572bb331b&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

❓ **주키퍼에서 다수의 카프카 클러스터를 사용하는 방법**

주키퍼의 서로 다른 znode에 카프카 클러스터들을 설정하면 된다. 

2개 이상의 카프카 클러스터를 구축할 때에는 root znode가 아닌 한 단계 아래의 znode를 카프카 브로커 옵션으로 지정하도록 한다. 

예) 파이프라인용 카프카 클로스터: zookeeper.connect=localhost:2181/pipeline 

      실시간 추천용 카프카 클러스터: zookeeper.connect=localhost:2191/recommend 

# 3.2 토픽과 파티션

- **토픽**: 카프카에서 데이터를 구분하기 위해 사용하는 단위. 토픽은 1개 이상의 파티션을 소유하고 있다.
- **파티션**: 프로듀서가 보낸 데이터들이 들어가 저장된다. 이 때 데이터를 '레코드(record)'라고 부른다. → 카프카 병렬처리의 핵심!!
- 컨슈머의 처리량이 한정된 상황에서 많은 레코드를 병렬로 처리하는 가장 좋은 방법은 컨슈머의 개수를 늘려 스케일 아웃하는 것이다. 동시에 파티션 개수도 늘리면 처리량이 증가한다.

![4](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7d4a17fc-dcaf-434c-a1c9-4ebedcc10700/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210724%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210724T124250Z&X-Amz-Expires=86400&X-Amz-Signature=12d2947dfa43ad21391fbf44fac8d9e55f5bb93b8d15026edaa3b7853e8f2736&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- 파티션은 큐와 비슷한 구조. FIFO

⚠️ **토픽 이름 제약 조건**

- 빈 문자열 X
- 마침표 하나(.) 또는 마침표 둘(..) X
- 249자 미만
- 영어 대소문자, 숫자 0~9, 마침표(.), 언더바(_), 하이픈(-) 조합으로 생성 가능
- ___consumer_offsets, __transaction_state과 동일한 이름으로 생성 불가능
- 마침표, 언더바 동시 사용 불가능
- 예를 들어, to.pic이 있다면 to_pic은 생성 불가능

‼️ 토픽 작명의 템플릿

- <환경>.<팀-명>.<애플리케이션-명>.<메시지-타입>

    예) prd.marketing-team.sms-platform.json

- <프로젝트-명>.<서비스-명>.<환경>.<이벤트-명>

    예) commerce.payment.prd.notification

- <환경>.<서비스-명>.<JIRA-번호>.<메시지-타입>

    예) dev.email-sender.jira-1234.email-vo-custom

- <카프카-클러스터-명>.<환경>.<서비스-명>.<메시지-타입>

    예) aws-kafka.live.marketing-platform.json

# 3.3 레코드

- 레코드는 타임스탬프, 메시지 키, 메시지 값, 오프셋으로 구성되어 있다
- 프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋과 타임스탬프가 지정되어 저장된다.
- 브로커에 한 번 적재된 레코드는 수정할 수 없고 로그 리텐션 기간 또는 용량에 따라서만 삭제된다.
- **타임스탬프**: 브로커 기준 유닉스 시간
- **메시지 키**: 메시지 값을 순서대로 처리하거나 메시지 값의 종류를 나타내기 위해 사용. 프로듀서가 토픽에 레코드를 전송할 대 메시지 키의 해시값을 토대로 파티션을 지정하게 된다.
- **메시지 값**: 실질적으로 처리할 데이터. 메시지 키와 메시지 값은 직렬화되어 브로커로 전송되기 때문에 컨슈머가 이용할 때는 직렬화한 형태와 동일한 형태로 역직렬화를 수행해야 한다.
- **오프셋**: 0 이상의 숫자로 이루어져 있다. 브로커에 저장될 때 이전에 전송된 레코드의 오프셋 + 1 값으로 생성된다. 카프카 컨슈머가 데이터를 가져갈 때 사용된다.

# 3.4 카프카 클라이언트

카프카 클라이언트는 카프카 프로듀서, 컨슈머, 어드민 클라이언트를 제공하며, 라이브러리이다. 

## 3.4.1 프로듀서 API

- 카프카에 필요한 데이터를 선언하고 브로커의 특정 토픽의 파티션에 전송
- 프로듀서는 리더 파티션을 가지고 있는 카프카 브로커와 직접 통신

### 카프카 프로듀서 프로젝트 생성

1. 인텔리제이를 열어 New Project를 누른다. 
2. 좌측 탭에서 Gradle을 선택하고, Java를 선택한다. 
3. GroupId, ArtifactId, Version을 설정한다.
4. 프로젝트 이름과 프로젝트를 생성할 디렉토리를 설정한다. 
5. Gradle 기반 프로젝트 생성 완료!

### simple-kafka-producer

- build.gradle: 프로젝트를 빌드하기 위한 작업이나 디펜던시 정의
- settings.gradle: gradle로 생성한 프로젝트의 구조 선언
- src/main/java: 작성한 코드가 들어갈 디렉토리

```java
package com.example;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Properties;

public class SimpleProducer {
    private final static Logger logger = LoggerFactory.getLogger(SimpleProducer.class);
		// 전송하고자 하는 토픽 이름
    private final static String TOPIC_NAME = "test";
		// 전송하고자 하는 카프카 클러스터 서버의 host와 ip
    private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";

    public static void main(String[] args) {
				
				// Kafka Producer 인스턴스를 생성하기 위한 프로듀서 옵션들을 key/value 값으로 선언
        Properties configs = new Properties();
				// 전송하고자 하는 카프카 클러스터 서버의 host와 ip
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
				// 메시지 키, 메시지 값을 직렬화하기 위한 직렬화 클래스를 선언
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        // 메시지 키, 메시지 값을 직렬화하기 위한 직렬화 클래스를 선언
				configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
				
				// Properties를 KafkaProducer의 생성 파라미터로 추가하여 인스턴스를 생성
        KafkaProducer<String, String> producer = new KafkaProducer<>(configs);
				
				// 메시지 값 선언
        String messageValue = "testMessage";
				// 카프카 브로커로 데이터를 보내기 위해 ProducerRecord를 생성
        ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, messageValue);
        // send(record): 파라미터로 들어간 record를 프로듀서 내부에 가지고 있다가 배치 형태로 묶어서 전송
				producer.send(record);
        logger.info("{}", record);
				// 프로듀서 내부 버퍼에 가지고 있던 레코드 배치를 브로커로 전송
        producer.flush();
				// producer 인스턴스의 리소스들을 안전하게 종료
        producer.close();
    }
}
```

- 로컬에서 토픽을 생성한 후 위의 프로듀서를 실행하여 데이터를 전송한다. 카프카 프로듀서 애플리케이션이 실행되면서 카프카 라이브러리 로그가 출력된다.

### 프로듀서 중요 개념

- 프로듀서는 카프카 브로커로 데이터를 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거친다.

![5](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6ecc9777-e255-4c58-bc99-415b82226cf7/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210724%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210724T124326Z&X-Amz-Expires=86400&X-Amz-Signature=a7560bad11297851b3868250a1f97189f12f8810662e3f24b5b11ce99958ca77&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- ProducerRecord 클래스를 통해 인스턴스를 생헝하고, 토픽과 메시지 값을 설정한다.
- ProducerRecord 생성 시 추가 파라미터를 사용하여 파티션 번호를 직접 지저하거나 타임스탬프를 설정, 메시지 키를 설정할 수도 있다.
- KafkaProducer 인스턴스가 send() 메서드를 호출하면 ProducerRecord는 파티셔너에서 토픽의 어느 파티션으로 전송될 것인지 정해진다.
- 파티셔너에 의해 구분된 레코드는 데이터를 전송하기 전에 어큐뮬레이터에 데이터를 버퍼로 쌓아놓고 발송한다. 버퍼로 쌓인 데이터는 배치로 묶어서 전송한다.
- sender 스레드는 어큐뮬레이터에 쌓인 배치 데이터를 가져가 카프카 브로커로 전송한다.
- UniformStickyPartitioner/RoundRobinPartitioner → UniformStickyPartitioner는 배치로 묶어 데이터를 전송함으로써 RRPartitioner의 단점 개선

### 프로듀서 주요 옵션

- **필수 옵션**
    - bootstrap.server: 브로커의 호스트 이름:포트
    - key.serializer: 레코드의 메시지 키 직렬화하는 클래스
    - value.serializer: 레코드의 메시지 값 직렬화하는 클래스
- **선택 옵션**
    - acks: 전송 성공 여부 확인
    - buffer.memory: 버퍼 메모리양
    - retries: 재전송 시도하는 횟수
    - batch.size: 배치로 전송할 레코드 최대 용량
    - linger.ms: 배치 전송 전까지 기다리는 최소 시간
    - partitioner.class: 파티셔너 클래스
    - enable.idempotence: 멱등성 프로듀서로 동작할지 여부
    - transactional.id: 전송 시 레코드를 트랜잭션 단위로 묶을지 여부

### 메시지 키를 가진 데이터를 전송하는 프로듀서

- 메시지 키가 포함된 레코드를 전송하고 싶다면 ProducerRecord 생성 시 파라미터로 추가해야 한다.
- 토픽 이름, 메시지 키, 메시지 값 순서

```java
ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, "Pangyo", "23");
```

- 파티션을 직접 지정하고 싶다면 토픽 이름, 파티션 번호, 메시지 키, 메시지 값을 순서대로 파라미터로 넣고 생성하면 된다.

```java
int partitionNo = 0;
ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, partitionNo, "Pangyo", "23");
```

### 커스텀 파티셔너를 가지는 프로듀서

- 특정 데이터를 가지는 레코드를 특정 파티션으로 보내는 경우

```java
package com.example;

import org.apache.kafka.clients.producer.Partitioner;
import org.apache.kafka.common.Cluster;
import org.apache.kafka.common.InvalidRecordException;
import org.apache.kafka.common.PartitionInfo;
import org.apache.kafka.common.utils.Utils;

import java.util.List;
import java.util.Map;

public class CustomPartitioner  implements Partitioner {

    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes,
                         Cluster cluster) { // 레코드를 기반으로 파티션 정하기

				// 메시지 키를 지정하지 않은 경우 비정상적인 데이터로 간주
        if (keyBytes == null) {
            throw new InvalidRecordException("Need message key");
        }
				// 메시지 키가 Pangyo일 경우 파티션 0번으로 지정
        if (((String)key).equals("Pangyo"))
            return 0;

        List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
        int numPartitions = partitions.size();
				// Pangyo가 아닌 메시지 키를 가진 레코드는 해시값을 지정하여 특정 파티션에 매칭
        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
    }

    @Override
    public void configure(Map<String, ?> configs) {}

    @Override
    public void close() {}
}
```

- 커스텀 파티셔너를 지정한 경우 ProducerConfig의 PARTITIONER_CLASS_CONFIG 옵션을 사용자 생성 파티셔너로 설정하여 KafkaProducer 인스턴스를 생성해야 한다.

```java
Properties configs = new Properties();
configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
configs.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, CustomPartitioner.class);
```

### 브로커 정상 전송 여부를 확인하는 프로듀서

- send() 메서드는 Future 객체를 반환하는데, 여기에는 ProducerRecord가 카프카 브로커에 정상적으로 적재되었는지에 대한 데이터가 포함되어 있다.
- get() 메서드를 사용하면 프로듀서로 보낸 데이터의 결과를 동기적으로 가져올 수 있다.

```java
ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, "Pangyo", "23");
RecordMetadata metadata = producer.send(record).get();
logger.info(metadata.toString());
```

- 레코드가 정상적으로 적재되었다면 토픽 이름, 파티션 번호, 오프셋 번호가 출력된다.
- 그러나 동기로 프로듀서의 전송 결과를 확인하는 것은 빠른 전송에 허들이 될 수 있다.
- 따라서 이를 원하지 않는 경우 비동기로 결과를 확인할 수 있다.

```java
public class ProducerCallback implements Callback {
    private final static Logger logger = LoggerFactory.getLogger(ProducerCallback.class);

    @Override
    public void onCompletion(RecordMetadata recordMetadata, Exception e) {
        if (e != null)
            logger.error(e.getMessage(), e);
        else
            logger.info(recordMetadata.toString());
    }
}
```

- 위의 코드에서는 만약 브로커 적재에 이슈가 생겼을 경우 Exception에 어떤 에러가 발생하였는지 담겨서 메서드가 실행된다.
- 에러가 발생하지 않았을 경우 RecordMetadata를 통해 해당 레코드가 적재된 토픽 이름, 파티션 번호, 오프셋을 알 수 있다.

```java
KafkaProducer<String, String> producer = new KafkaProducer<>(configs);
ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, "Pangyo", "23");
producer.send(record, new ProducerCallback());
```

- 레코드 전송 후 비동기로 결과를 받기 위해서는 send() 메서드 호출 시 ProducerRecord 객체와 함께 사용자 정의 Callback 클래스를 넣으면 된다.
- 이 방식은 데이터의 순서가 중요한 경우 사용하면 안 된다.

## 3.4.2 컨슈머 API

- 컨슈머는 적재된 데이터를 사용하기 위해 브로커로부터 데이터를 가져와서 필요한 처리를 한다.

### 카프카 컨슈머 프로젝트 생성

- 프로듀서처럼 자바 어플리케이션을 만든다.

```java
package com.example;

import com.google.gson.Gson;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;

public class SimpleConsumer {
    private final static Logger logger = LoggerFactory.getLogger(SimpleConsumer.class);
    private final static String TOPIC_NAME = "test";
    private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";
		// 컨슈머 그룹을 통해 컨슈머의 목적을 구분할 수 있다. 
    private final static String GROUP_ID = "test-group";

    public static void main(String[] args) {
        Properties configs = new Properties();
        configs.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        configs.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);
				// 프로듀서가 직렬화하여 전송한 데이터를 역직렬화하기 위해 역직렬화 클래스를 작성
        configs.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        configs.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

				// Properties로 지정한 카프카 컨슈머 옵션을 파라미터로 받아 KafkaConsumer 인스턴스를 생성
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);
				// 컨슈머에게 토픽을 할당하기 위해 subscribe() 메서드를 사용
        consumer.subscribe(Arrays.asList(TOPIC_NAME));

        while (true) { // 지속적 처리를 위해 while 사용
						// poll() 메서드를 호출하여 데이터를 가져와서 처리
						// 컨슈머는 poll() 메서드를 통해 ConsumerRecord 리스트를 반환
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
            // poll() 메서드가 반환한 ConsumerRecord 데이터들을 순차적으로 처리
						for (ConsumerRecord<String, String> record : records) {
                logger.info("record:{}", record);
            }
        }
    }
}
```

- 컨슈머를 실행시키면 카프카 라이브러리 로그가 출력됨과 동시에 컨슈머가 test 토픽을 구독하면서 브로커로부터 polling을 시작한다.

### 컨슈머 중요 개념

- **컨슈머 운영 방법**
    1. 1개 이상의 컨슈머로 이루어진 컨슈머 그룹을 운영
        1. 컨슈머를 각 컨슈머 그룹으로부터 격리된 환경에서 안전하게 운영한다. 
        2. 컨슈머 그룹으로 묶인 컨슈머들은 토픽의 1개 이상 파티션들에 할당되어 데이터를 가져갈 수 있다. 
        3. 1개의 파티션은 최대 1개의 컨슈머에 할당 가능하다.
        4. 1개의 컨슈머는 여러 개의 파티션에 할당될 수 있다. 
        5. 컨슈머 그룹의 컨슈머 개수는 가져가고자 하는 토픽의 파티션 개수보다 같거나 작아야 한다. 
        6. 컨슈머 그룹은 다른 컨슈머 그룹과 격리되어 각기 다른 역할을 하는 컨슈머 그룹끼리 영향을 받지 않게 데이터를 처리할 수 있다. 

        ![6](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e4f0076d-d11c-48f2-b675-bc1c66a0a9e4/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210724%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210724T124337Z&X-Amz-Expires=86400&X-Amz-Signature=dd2fdd247dd1d2602deb78cb80359f1cd8ad61bf63d261ab108800d66ac5968d&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

    2. 토픽의 특정 파티션만 구독하는 컨슈머를 운영
- **리밸런싱(rebalancing)**: 컨슈마가 추가 또는 제외되었을 때 파티션을 컨슈머에 재할당
- 그룹 조정자(group coordinator)는 리밸런싱을 발동시키는 역할을 하는데 컨슈머 그룹의 컨슈머가 추가되고 삭제될 때를 감지한다. 브로커 중 한 대가 그룹 조정자의 역할을 수행한다.
- 컨슈머는 카프카 브로커로부터 데이터를 어디까지 가져갔는지 커밋(commit)을 통해 기록한다. 특정 토픽의 파티션을 어떤 컨슈머 그룹이 몇 번째 가져갔는지 카프카 브로커 내부에 사용되는 내부 토픽(__consumer_offsets)에 기록된다.

![7](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/aca357b3-2f56-4ddc-bc94-edd5b9bd8970/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210724%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210724T124341Z&X-Amz-Expires=86400&X-Amz-Signature=acb2e45d65318d7273a7207c6fc75347153686518699a25fb52788577cf8472b&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

- 오프셋 커밋은 명시적, 비명시적으로 수행할 수 있다.
    - 비명시 오프셋 커밋: 일정 간격마다 자동 커밋
    - 비명시 오프셋 커밋은 편리하지만 poll() 메서드 호출 이후에 리밸런싱 또는 컨슈머 강제종료 발생 시 컨슈머가 처리하는 데이터가 중복 또는 유실될 수 있는 가능성이 있다.
    - 명시적 오프세 커밋을 위해서는 poll() 메서드 호출 이후에 반환 받은 데이터의 처리가 완료되고 commitSync() 메서드를 호출하면 된다.
    - commitSync() 메서드는 응답하기까지 기다리는 시간으로 인해 컨슈머의 처리량에 영향을 끼친다. 이를 해결하기 위해 commitAsync() 메서드를 사용하여 커밋 요청을 전송하고 응답이 오기 전까지 데이터 처리를 수행할 수 있다. 하지만 이는 데이터의 순서를 보장하지 않으며 중복 처리가 발생할 수 있다.
- 컨슈머는 poll() 메서드를 통해 레코드들을 반환받지만 poll() 메서드를 호출하는 시점에 클러스터에서 데이터를 가져오는 것은 아니다.

### 컨슈머 주요 옵션

- **필수 옵션**
    - bootstrap.servers: 브로커 호스트 이름:포트
    - key.deserializer: 레코드의 메시지 키 역직렬화하는 클래스 지정
    - value.deserializer: 레코드의 메시지 값 역직렬화하는 클래스 지정
- **선택 옵션**
    - group.id: 컨슈머 그룹 아이디 지정
    - auto.offset.reset: 저장된 컨슈머 오프셋이 없는 경우 어느 오프셋부터 읽을지 선택
    - enable.auto.commit: 자동 커밋/수동 커밋 선택
    - auto.commit.interval.ms: 자동커밋일 경우 오프셋 커밋 간격 지정
    - max.poll.records: poll() 메서드를 통해 반환되는 레코드 개수 지정
    - session.timeout.ms: 컨슈머가 브로커와 연결이 끊기는 최대 시간. 이 시간 내에 하트비트 전송하지 않으면 리밸런싱을 시작.
    - heartbeat.interval.ms: 하트비트를 전송하는 시간 간격
    - max.poll.interval.ms: poll() 메서드를 호출하는 간격의 최대 시간 지정
    - isolation.level: 트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 경우 사용

### 동기 오프셋 커밋

- poll() 메서드가 호출된 이후에 commitSync() 메서드를 호출하여 오프셋 커밋 수행 가능

```java
configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);

KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);
consumer.subscribe(Arrays.asList(TOPIC_NAME));

while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
    for (ConsumerRecord<String, String> record : records) {
        logger.info("record:{}", record);
    }
    consumer.commitSync();
}
```

- 브로커로부터 컨슈머 오프셋 커밋이 완료되었음을 받기까지 컨슈머는 데이터를 더 처리하지 않고 기다리기 때문에 자동 커밋이나 비동기 오프셋 커밋보다 동일 시간당 데이터 처리량이 적다.
- 개별 레코드 단위로 매번 오프셋을 커밋하고 싶다면, commitSync() 메서드에 Map<TopicPartition, OffsetAndMetadata> 인스턴스를 파라미터로 넣으면 된다.

```java
configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);

KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);
consumer.subscribe(Arrays.asList(TOPIC_NAME));

while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
    Map<TopicPartition, OffsetAndMetadata> currentOffset = new HashMap<>();

    for (ConsumerRecord<String, String> record : records) {
        logger.info("record:{}", record);
        currentOffset.put(
                new TopicPartition(record.topic(), record.partition()),
                new OffsetAndMetadata(record.offset() + 1, null));
        consumer.commitSync(currentOffset);
    }
}
```

### 비동기 오프셋 커밋

- 동기 오프셋 커밋보다 더 많은 데이터 처리를 위해서 사용
- 비동기 오프셋 커밋은 commitAsync() 메서드를 호출하여 사용할 수 있다.
- 비동기 오프셋 커밋은 커밋이 완료될 때까지 응답을 기다리지 않는다.
- 비동기로 커밋 응답을 받기 때문에 callback 함수를 파라미터로 받아서 결과를 얻을 수 있다.

```java
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
    for (ConsumerRecord<String, String> record : records) {
        logger.info("record:{}", record);
    }
    consumer.commitAsync(new OffsetCommitCallback() {
        public void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets, Exception e) {
            if (e != null)
                System.err.println("Commit failed");
            else
                System.out.println("Commit succeeded");
            if (e != null)
                logger.error("Commit failed for offsets {}", offsets, e);
        }
    });
}
```

### 리밸런스 리스너를 가진 컨슈머

- 리밸런스 발생 시 데이터를 중복처리하지 않게 하기 위해서는 리밸런스 발생 시 처리한 데이터를 기준으로 커밋을 시도해야 한다.
- 리밸런스 발생을 감지하기 위해 ConsumerRebalanceListener 인터페이스를 사용한다.
    - onPartitionAssigned(): 리밸런스가 끝난 뒤에 파티션이 할당 완료되면 호출되는 메서드
    - onPartitionRevoked(): 리밸런스가 시작되기 직전에 호출되는 메서드
- 마지막으로 처리한 레코드를 기준으로 커밋을 하기 위해서는 리밸런스가 시작하기 직전에 커밋을 하면 되므로 onPartitionRevoked() 메서드에 커밋을 구현하여 처리할 수 있다.

```java
public static void main(String[] args) {
    Properties configs = new Properties();
		...
		configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);

		consumer = new KafkaConsumer<>(configs);
    consumer.subscribe(Arrays.asList(TOPIC_NAME), new RebalanceListener());
    while (true) {
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
        for (ConsumerRecord<String, String> record : records) {
            logger.info("{}", record);
            currentOffsets.put(new TopicPartition(record.topic(), record.partition()),
                    new OffsetAndMetadata(record.offset() + 1, null));
            consumer.commitSync(currentOffsets);
        }
    }
}

public class RebalanceListener implements ConsumerRebalanceListener {
		public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
        logger.warn("Partitions are assigned");

    }

    public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
        logger.warn("Partitions are revoked");
        consumer.commitSync(currentOffsets);
    }
}
```

### 파티션 할당 컨슈머

- 컨슈머가 어던 토픽, 파티션을 할당할지 명시적으로 선언할 때는 assign() 메서드를 사용하면 된다.

```java
private final static String TOPIC_NAME = "test";
private final static int PARTITION_NUMBER  = 0;

KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);
consumer.assign(Collections.singleton(new TopicPartition(TOPIC_NAME, PARTITION_NUMBER)));
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
    for (ConsumerRecord<String, String> record : records) {
        logger.info("record:{}", record);
    }
}
```

### 컨슈머에 할당된 파티션 확인 방법

- 컨슈머에 할당된 토픽과 파티션에 대한 정보는 assignment() 메서드로 확인할 수 있다.

```java
KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);
consumer.subscribe(Arrays.asList(TOPIC_NAME));
Set<TopicPartition> assignedTopicPartition = consumer.assignment();
```

### 컨슈머의 안전한 종료

- 정상적으로 종료되지 않은 컨슈머는 컨슈머 그룹에 남게 되는데, 이로 인해 컨슈머 랙이 늘어나 데이터 처리 지연이 발생하게 된다.
- 따라서 컨슈머 애플리케이션은 wakeup(), close() 메서드를 이용해 안전하게 종료되어야 한다.

```java
public static void main(String[] args {
		Runtime.getRuntime().addShutdownHook(new ShutdownThread());

		...

		try {
		    while (true) {
		        ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
		        for (ConsumerRecord<String, String> record : records) {
		            logger.info("{}", record);
		        }
		    }
		} catch (WakeupException e) {
		    logger.warn("Wakeup consumer");
		} finally {
		    consumer.close();
		}
}

static class ShutdownThread extends Thread {
    public void run() {
        logger.info("Shutdown hook");
        consumer.wakeup();
    }
}
```

## 3.4.3 어드민 API

- 카프카에 설정된 내부 옵션을 설정하고 조회하기 위해 AdminClient 클래스를 제공한다.
- 클러스터의 옵션과 관련된 부분을 자동화할 수 있다.

‼️ **사용 예시**

- 카프카 컨슈머를 멀티 스레드로 생성할 때, 구독하는 토픽의 파티션 개수만큼 스레드를 생성하고 싶을 때, 스레드 생성 전에 해당 토픽의 파티션 개수를 어드민 API를 통해 가져올 수 있다.
- AdminClient 클래스로 구현한 웹 대시보드를 통해 ACL(Access Control List)이 적용된 클러스터의 리소스 접근 권한 규칙 추가를 할 수 있다.
- 특정 토픽의 데이터 양이 늘어남을 감지하고 AdminClient 클래스로 해당 토픽의 파티션을 늘릴 수 있다.

### 어드민 API 선언 방법

```java
Properties configs = new Properties();
configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "my-kafka:9092");
AdminClient admin = AdminClient.create(configs);
```

[KafkaAdminClient 주요 메서드](https://www.notion.so/61032a1f2cde4404b0a0898328c5b149)

### 브로커 정보 조회

```java
Properties configs = new Properties();
configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "my-kafka:9092");
AdminClient admin = AdminClient.create(configs);
logger.info("== Get broker information");
for (Node node : admin.describeCluster().nodes().get()) {
		logger.info("node : {}", node);
    ConfigResource cr = new ConfigResource(ConfigResource.Type.BROKER, node.idString());
		DescribeConfigsResult describeConfigs = admin.describeConfigs(Collections.singleton(cr));
		describeConfigs.all().get().forEach((broker, config) -> {
        config.entries().forEach(configEntry -> logger.info(configEntry.name() + "= " + configEntry.value()));
    });
}
```

### 토픽 정보 조회

```java
logger.info("== test topic information");
Map<String, TopicDescription> topicInformation = admin.describeTopics(Collections.singletonList("test")).all().get();
logger.info("{}", topicInformation);
```

‼️ 어드민 API는 사용하고 나면 명시적으로 종료 메서드를 호출하여 리소스가 낭비되지 않도록 한다. 

```java
admin.close()
```